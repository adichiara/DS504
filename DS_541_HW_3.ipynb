{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS 541 - HW 3",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adichiara/DS504/blob/main/DS_541_HW_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_bPxfmil09t"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import eye as eye\n",
        "from numpy.linalg import inv as inv\n",
        "from numpy.linalg import solve as solve\n",
        "from numpy.linalg import eig as eig\n",
        "from numpy.linalg import matrix_power\n",
        " \n",
        "from numpy import random\n",
        "from numpy.random import randn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CgPvDD5KKu9"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        " \n",
        "import requests\n",
        "import urllib\n",
        "from urllib.parse import urlparse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVWjhXZX_y3V"
      },
      "source": [
        "\r\n",
        "def load_data():\r\n",
        "    # Load data\r\n",
        "\r\n",
        "    urllib.request.urlretrieve('https://s3.amazonaws.com/jrwprojects/fashion_mnist_train_images.npy', 'fashion_mnist_train_images.npy')\r\n",
        "    urllib.request.urlretrieve('https://s3.amazonaws.com/jrwprojects/fashion_mnist_test_images.npy', 'fashion_mnist_test_images.npy')\r\n",
        "    urllib.request.urlretrieve('https://s3.amazonaws.com/jrwprojects/fashion_mnist_train_labels.npy', 'fashion_mnist_train_labels.npy')\r\n",
        "    urllib.request.urlretrieve('https://s3.amazonaws.com/jrwprojects/fashion_mnist_test_labels.npy', 'fashion_mnist_test_labels.npy')\r\n",
        "\r\n",
        "    X_tr = np.reshape(np.load('fashion_mnist_train_images.npy'), (-1, 28*28))\r\n",
        "    X_te = np.reshape(np.load('fashion_mnist_test_images.npy'), (-1, 28*28))\r\n",
        "    y_tr = np.load('fashion_mnist_train_labels.npy')\r\n",
        "    y_te = np.load('fashion_mnist_test_labels.npy')\r\n",
        "\r\n",
        "    return ([X_tr, X_te, y_tr, y_te])\r\n",
        "\r\n",
        "X_tr, X_te, y_tr_scalar, y_te_scalar = load_data()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIHcFdfLFE4A"
      },
      "source": [
        "\r\n",
        "\r\n",
        "def one_hot_encode_y(y_tr_scalar, y_te_scalar, max_num):\r\n",
        "    y_tr = (np.eye(max_num)[y_tr_scalar]).astype(int)\r\n",
        "    y_te = (np.eye(max_num)[y_te_scalar]).astype(int)\r\n",
        "    return ([y_tr, y_te])\r\n",
        "\r\n",
        "\r\n",
        "def training_validation_splits(X, y, train_pct):\r\n",
        "    split_num = int(np.round(X.shape[0] * train_pct,0))\r\n",
        "    all_idx = random.permutation(X.shape[0])\r\n",
        "    tr_idx, te_idx = all_idx[:split_num], all_idx[split_num:]\r\n",
        "    X_tr, X_val = X[tr_idx,:], X[te_idx,:]\r\n",
        "    y_tr, y_val = y[tr_idx], y[te_idx]\r\n",
        "    return ([X_tr, X_val, y_tr, y_val])\r\n",
        "\r\n",
        "\r\n",
        "def randomize_dataset_order(X, y):\r\n",
        "    all_idx = random.permutation(X.shape[0])\r\n",
        "    return ([X[all_idx], y[all_idx]])\r\n",
        "\r\n",
        "\r\n",
        "def softmax_regression(X_tr, X_te, y_tr, y_te):\r\n",
        "\r\n",
        "    # generate initial randomized weights and compute bias\r\n",
        "    w = np.random.rand(X_tr.shape[1], 1,10)\r\n",
        "\r\n",
        "\r\n",
        "    \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "y_tr, y_te = one_hot_encode_y(y_tr_scalar, y_te_scalar, 10)\r\n",
        "\r\n",
        "softmax_regression(X_tr, X_te, y_tr, y_te)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvVJ4XpMxz_H"
      },
      "source": [
        "\r\n",
        "### HW 2 code\r\n",
        "\r\n",
        "def training_validation_splits(X, y, train_pct):\r\n",
        "    split_num = int(np.round(X.shape[0] * train_pct,0))\r\n",
        "    all_idx = random.permutation(X.shape[0])\r\n",
        "    tr_idx, te_idx = all_idx[:split_num], all_idx[split_num:]\r\n",
        "    X_tr, X_val = X[tr_idx,:], X[te_idx,:]\r\n",
        "    y_tr, y_val = y[tr_idx], y[te_idx]\r\n",
        "    return ([X_tr, X_val, y_tr, y_val])\r\n",
        "\r\n",
        "\r\n",
        "def randomize_dataset_order(X, y):\r\n",
        "    all_idx = random.permutation(X.shape[0])\r\n",
        "    return ([X[all_idx], y[all_idx]])\r\n",
        "\r\n",
        "\r\n",
        "def compute_bias(X, y, w):\r\n",
        "    b = np.mean(y - X.dot(w))\r\n",
        "    return (b)\r\n",
        "\r\n",
        "\r\n",
        "def update_weights(X, y, w, b, L2_alpha, learning_rate):\r\n",
        "    n = X.shape[0]\r\n",
        "    m = X.shape[1]\r\n",
        "    # orient X as design matrix (m x n)\r\n",
        "    X = X.T\r\n",
        "    # convert to column vectors\r\n",
        "    y = np.atleast_2d(y).T\r\n",
        "    w = np.atleast_2d(w).T\r\n",
        "    b = np.atleast_2d(b).T\r\n",
        "\r\n",
        "    yhat = X.T.dot(w) + b\r\n",
        "    L2_reg = L2_alpha/n * w \r\n",
        "\r\n",
        "    gradient = ((X.dot(yhat - y)) + L2_reg) / n\r\n",
        "    w_new = w - learning_rate * gradient\r\n",
        "    w_new = w_new[:,0]  # convert 2D (nx1) matrix to 1D vector \r\n",
        "    return w_new\r\n",
        "\r\n",
        "\r\n",
        "def compute_fMSE(X, y, w, b, L2_alpha):\r\n",
        "    n = X.shape[0]\r\n",
        "    m = X.shape[1]   \r\n",
        "    # orient X as design matrix (m x n)\r\n",
        "    X = X.T\r\n",
        "    # convert to column vectors\r\n",
        "    y = np.atleast_2d(y).T\r\n",
        "    w = np.atleast_2d(w).T\r\n",
        "    b = np.atleast_2d(b).T\r\n",
        "\r\n",
        "    yhat = X.T.dot(w) + b\r\n",
        "    L2_reg = 1/(2*n) * L2_alpha * w.T.dot(w) \r\n",
        "\r\n",
        "    mse = (np.sum(np.power((yhat - y),2)) + L2_reg) / (2*n)\r\n",
        "    mse = mse[0,0]  # convert 2D (1x1) matrix to scalar\r\n",
        "    return mse\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def train_age_regressor(epoch_list, batch_size_list, L2_alpha_list, learning_rate_list):\r\n",
        "    # Load data\r\n",
        "\r\n",
        "    urllib.request.urlretrieve('https://s3.amazonaws.com/jrwprojects/fashion_mnist_train_images.npy', 'fashion_mnist_train_images.npy')\r\n",
        "    urllib.request.urlretrieve('https://s3.amazonaws.com/jrwprojects/fashion_mnist_test_images.npy', 'fashion_mnist_test_images.npy')\r\n",
        "    urllib.request.urlretrieve('https://s3.amazonaws.com/jrwprojects/fashion_mnist_train_labels.npy', 'fashion_mnist_train_labels.npy')\r\n",
        "    urllib.request.urlretrieve('https://s3.amazonaws.com/jrwprojects/fashion_mnist_test_labels.npy', 'fashion_mnist_test_labels.npy')\r\n",
        "\r\n",
        "    X_tr = np.load('fashion_mnist_train_images.npy')\r\n",
        "    X_te = np.load('fashion_mnist_test_images.npy')\r\n",
        "    y_tr = np.load('fashion_mnist_train_labels.npy')\r\n",
        "    y_te =  np.load('fashion_mnist_test_labels.npy')\r\n",
        "\r\n",
        "    # X_tr = np.reshape(np.load(\"age_regression_Xtr.npy\"), (-1, 48*48))\r\n",
        "    # y_tr = np.load(\"age_regression_ytr.npy\")\r\n",
        "    # X_te = np.reshape(np.load(\"age_regression_Xte.npy\"), (-1, 48*48))\r\n",
        "    # y_te = np.load(\"age_regression_yte.npy\")\r\n",
        "\r\n",
        "    # make train/val/test splits (80% train vs val)\r\n",
        "    X_tr, X_val, y_tr, y_val = training_validation_splits(X_tr, y_tr, .8)\r\n",
        "\r\n",
        "    \r\n",
        "    # generate initial randomized weights and compute bias\r\n",
        "    w = np.random.rand(X_tr.shape[1])\r\n",
        "    b = compute_bias(X_tr, y_tr, w)\r\n",
        "\r\n",
        "\r\n",
        "    # hyperparameter iterative grid search\r\n",
        "    max_iterations = (len(epoch_list) * \r\n",
        "                      len(batch_size_list) * \r\n",
        "                      len(L2_alpha_list) * \r\n",
        "                      len(learning_rate_list))\r\n",
        "    current_iter = 0\r\n",
        "    tuning_results_list = []  # for logging mse validation results of each hyperparameter combo\r\n",
        "\r\n",
        "    for learning_rate in learning_rate_list:\r\n",
        "      for L2_alpha in L2_alpha_list:\r\n",
        "        for batch_size in batch_size_list:\r\n",
        "          print('\\n')\r\n",
        "          for num_epochs in epoch_list:\r\n",
        "            for epoch in range(0, num_epochs):  \r\n",
        "              X_tr, y_tr = randomize_dataset_order(X_tr, y_tr)\r\n",
        "\r\n",
        "              for i in range(0, X_tr.shape[0], batch_size):\r\n",
        "                # compute gradient for each batch and update weights\r\n",
        "                w = update_weights(X_tr[i:i+batch_size,:], \r\n",
        "                                    y_tr[i:i+batch_size], \r\n",
        "                                    w, b, L2_alpha, learning_rate)\r\n",
        "                \r\n",
        "                b = compute_bias(X_tr[i:i+batch_size,:], \r\n",
        "                                  y_tr[i:i+batch_size], w)\r\n",
        "\r\n",
        "            # compute mse of trained model on validation set\r\n",
        "            mse_val = compute_fMSE(X_val, y_val, w, b, L2_alpha)\r\n",
        "\r\n",
        "            # output current mse results using these hyperparameters on validation set \r\n",
        "            print(str(current_iter+1).zfill(len(str(max_iterations))), \"of\", max_iterations,\r\n",
        "                  ' |  mse:', \"{:.3f}\".format(mse_val), \r\n",
        "                  ' |  learning_rate', \"{:.3f}\".format(learning_rate),\r\n",
        "                  ' |  L2_alpha', \"{:.3f}\".format(L2_alpha),\r\n",
        "                  ' |  batch_size', str(batch_size).zfill(3),\r\n",
        "                  ' |  num_epochs', str(num_epochs).zfill(3))\r\n",
        "\r\n",
        "            # if the current mse results are the best so far, record these hyperparameters\r\n",
        "            if (current_iter>0):  \r\n",
        "              if (mse_val < best_params['mse']):\r\n",
        "                best_params = {'num_epochs': num_epochs,\r\n",
        "                              'batch_size': batch_size,\r\n",
        "                              'L2_alpha': L2_alpha,\r\n",
        "                              'learning_rate': learning_rate,\r\n",
        "                              'mse': mse_val}  \r\n",
        "            else:\r\n",
        "              best_params = {'num_epochs': num_epochs,\r\n",
        "                            'batch_size': batch_size,\r\n",
        "                            'L2_alpha': L2_alpha,\r\n",
        "                            'learning_rate': learning_rate,\r\n",
        "                            'mse': mse_val}  \r\n",
        "                        \r\n",
        "            # log tuning results for after analysis\r\n",
        "            tuning_results = {'num_epochs': num_epochs,\r\n",
        "                              'batch_size': batch_size,\r\n",
        "                              'L2_alpha': L2_alpha,\r\n",
        "                              'learning_rate': learning_rate,\r\n",
        "                              'mse': mse_val}\r\n",
        "            tuning_results_list.append(tuning_results)\r\n",
        "            current_iter = current_iter + 1\r\n",
        "\r\n",
        "    #completed testing all hyperparameters - output summary results\r\n",
        "    print('\\n Hyperparameters tested:', \r\n",
        "          '\\n   num_epochs:', epoch_list,\r\n",
        "          '\\n   batch_size:', batch_size_list,\r\n",
        "          '\\n   L2_alpha:', L2_alpha_list,\r\n",
        "          '\\n   learning_rate:', learning_rate_list)\r\n",
        "    \r\n",
        "    print('\\n best_params:', \r\n",
        "          '\\n   num_epochs:', best_params['num_epochs'],\r\n",
        "          '\\n   batch_size:', best_params['batch_size'],\r\n",
        "          '\\n   L2_alpha:', best_params['L2_alpha'],\r\n",
        "          '\\n   learning_rate:', best_params['learning_rate'],\r\n",
        "          '\\n   mse:', best_params['mse'])\r\n",
        "    \r\n",
        "\r\n",
        "    # train model using best params\r\n",
        "    for epoch in range(0, best_params['num_epochs']):  \r\n",
        "      X_tr, y_tr = randomize_dataset_order(X_tr, y_tr)\r\n",
        "\r\n",
        "      for i in range(0, X_tr.shape[0], best_params['batch_size']):\r\n",
        "        # compute gradient for each batch and update weights\r\n",
        "        w = update_weights(X_tr[i:i+best_params['batch_size'],:], \r\n",
        "                           y_tr[i:i+best_params['batch_size']], \r\n",
        "                           w, b, best_params['L2_alpha'], \r\n",
        "                           best_params['learning_rate'])\r\n",
        "        \r\n",
        "        b = compute_bias(X_tr[i:i+best_params['batch_size'],:], \r\n",
        "                          y_tr[i:i+best_params['batch_size']], w)\r\n",
        "\r\n",
        "\r\n",
        "    # compute mse of trained model on test set\r\n",
        "    mse_test = compute_fMSE(X_te, y_te, w, b, best_params['L2_alpha'])\r\n",
        "    print(\"\\n MSE (test set):\", mse_test)\r\n",
        "\r\n",
        "    # return tuning results df\r\n",
        "    tuning_results_df = pd.DataFrame(tuning_results_list)\r\n",
        "    return(tuning_results_df)\r\n",
        "\r\n",
        "results = train_age_regressor(epoch_list = [5, 10, 50, 100],\r\n",
        "                              batch_size_list = [10, 50, 100, 200],\r\n",
        "                              L2_alpha_list = [.02, .05, .07, .1],\r\n",
        "                              learning_rate_list = [.0001, .001, .005, .01])\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THp_gZWoE34I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9wVT1vbgH1d"
      },
      "source": [
        "# # anaylitical solution for deriving w & b\r\n",
        "\r\n",
        "# def linear_regression_solve(X, y):\r\n",
        "#   # formula for deriving weights: (XX_t)^-1 Xy    \r\n",
        "#   X = X.T\r\n",
        "#   w = solve(X.dot(X.T), X.dot(y))\r\n",
        "#   b = np.mean(y - X.T.dot(w)) \r\n",
        "#   return ([w,b]) \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Err3VrNAZ6T"
      },
      "source": [
        "\r\n",
        "# plots to display tuning results for the hyperparameters tested \r\n",
        "\r\n",
        "sns.boxplot(data=results, x='num_epochs', y='mse')\r\n",
        "plt.yscale('log')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "sns.boxplot(data=results, x='batch_size', y='mse')\r\n",
        "plt.yscale('log')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "sns.boxplot(data=results, x='learning_rate', y='mse')\r\n",
        "plt.yscale('log')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "sns.boxplot(data=results, x='L2_alpha', y='mse')\r\n",
        "plt.yscale('log')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "g = sns.catplot(x=\"num_epochs\", y=\"mse\",\r\n",
        "                row=\"batch_size\", \r\n",
        "                col='learning_rate',\r\n",
        "                hue=\"L2_alpha\", \r\n",
        "                data=results, kind='strip',\r\n",
        "                height=3)\r\n",
        "plt.yscale('log')\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}